{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TDA 2016, January 21st, Leuven\n",
    "\n",
    "# &nbsp;\n",
    "\n",
    "# TensorOperations.jl:\n",
    "## Convenient tensor operations with Julia\n",
    "### (and fun with metaprogramming)\n",
    "\n",
    "# &nbsp;\n",
    "\n",
    "### Jutho Haegeman\n",
    "#### Department of Physics and Astronomy, UGent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "* **Motivation: Tensor Network Decompositions in Quantum Physics**\n",
    "* **Intro to the Julia Language**\n",
    "* **TensorOperations.jl**\n",
    "* **Implementation of basic tensor operations (with metaprogramming)**\n",
    "* **Optimization of tensor contraction order**\n",
    "* **Outlook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation: quantum many body physics\n",
    "* weirdness of quantum mechanics: Schrodinger's cat\n",
    "<img src=\"schrodinger.png\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Motivation: quantum many body physics\n",
    "* quantum bit ( = qubit):\n",
    "\n",
    "$$\\vert\\Psi\\rangle = \\alpha \\vert 0\\rangle + \\beta \\vert 1\\rangle\\quad\\text{with}\\quad\\alpha,\\beta\\in\\mathbb{C}$$\n",
    "\n",
    "* intrinsically indeterministic:\n",
    "\n",
    "    * $|\\alpha|^2$: probability of measuring 0\n",
    "    * $|\\beta|^2$: probability of measuring 1\n",
    "\n",
    "* for $N$ different qubits? \n",
    "\n",
    "$$\\vert\\Psi\\rangle = \\Psi_{00000}\\vert 00000 \\rangle + \\Psi_{00001} \\vert 00001\\rangle + \\ldots+ \\Psi_{11111} \\vert 11111\\rangle$$\n",
    "\n",
    "**$\\Rightarrow$ storing a quantum state of $N$ qubits requires $2^N$ complex numbers: $\\Psi_{i_1,i_2,\\ldots,i_{N}}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Motivation: quantum many body physics\n",
    "* quantum state is a high-order tensor / multidimensional array:\n",
    "  <img src=\"psi.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "* Curse of dimensionality: exponential scaling in $N$, the number of degrees of freedom (qubits, spins, atoms, ...)\n",
    "  \n",
    "* Realistic materials: $N$ is in the order of Avogadro's number, i.e. $O(10^{23})$\n",
    "  <img src=\"graphene.jpg\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Motivation: tensor network decompositions\n",
    "* graphical notation:\n",
    "    * matrix - vector multiplication: <img src=\"matvec.png\" style=\"width: 400px;\"/>\n",
    "    * matrix - matrix multiplication: <img src=\"matmat.png\" style=\"width: 400px;\"/>\n",
    "* tensor network decompositions for efficient description of quantum states\n",
    "  <img src=\"tn2.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the Julia Language\n",
    "\n",
    "  <img src=\"julia.png\" style=\"width: 200px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Selling point: dynamic high-level language with the speed of a statically-compiled language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Key features:\n",
    "    * Just-in-time compiled (using LLVM infrastructure)\n",
    "    * Dynamic type system\n",
    "    * Multiple dispatch:\n",
    "        * define function behavior across many combinations of argument types\n",
    "        * automatic generation of efficient, specialized code for different argument types\n",
    "    * Good support for computational science: numerics, statistics, multidimensional arrays, ...\n",
    "    * Homoiconic and powerful metaprogramming facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myabs2 (generic function with 2 methods)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function myabs(x)\n",
    "    if x < 0\n",
    "        return -x\n",
    "    end\n",
    "    return x\n",
    "end\n",
    "function myabs2(x::Real)\n",
    "    if x < 0\n",
    "        return -x\n",
    "    end\n",
    "    return x\n",
    "end\n",
    "function myabs2(x::Unsigned)\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "define i64 @julia_myabs_21601(i64) {\n",
      "top:\n",
      "  %1 = icmp sgt i64 %0, -1\n",
      "  br i1 %1, label %L, label %if\n",
      "\n",
      "if:                                               ; preds = %top\n",
      "  %2 = sub i64 0, %0\n",
      "  ret i64 %2\n",
      "\n",
      "L:                                                ; preds = %top\n",
      "  ret i64 %0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "code_llvm(myabs,Tuple{Int64}) # LLVM code for 64-bit integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "define i64 @julia_myabs_21626(i64) {\n",
      "L:\n",
      "  ret i64 %0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "code_llvm(myabs,Tuple{UInt64}) # LLVM code for 64-bit unsigned integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "define double @julia_myabs_21627(double) {\n",
      "top:\n",
      "  %1 = fcmp uge double %0, 0.000000e+00\n",
      "  br i1 %1, label %L, label %if\n",
      "\n",
      "if:                                               ; preds = %top\n",
      "  %2 = fmul double %0, -1.000000e+00\n",
      "  ret double %2\n",
      "\n",
      "L:                                                ; preds = %top\n",
      "  ret double %0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "code_llvm(myabs,Tuple{Float64}) # LLVM code for 64-bit floating point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Type inference & type stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " :($(Expr(:lambda, Any[:x], Any[Any[Any[:x,Float64,0],Any[symbol(\"##fy#7529\"),Float64,18]],Any[],Any[],Any[]], :(begin  # In[5], line 1:\n",
       "        ##fy#7529 = (Base.box)(Float64,(Base.sitofp)(Float64,0))\n",
       "        unless (Base.box)(Base.Bool,(Base.or_int)((Base.lt_float)(x::Float64,##fy#7529::Float64)::Bool,(Base.box)(Base.Bool,(Base.and_int)((Base.box)(Base.Bool,(Base.and_int)((Base.eq_float)(x::Float64,##fy#7529::Float64)::Bool,(Base.lt_float)(##fy#7529::Float64,9.223372036854776e18)::Bool)),(Base.slt_int)((Base.box)(Int64,(Base.fptosi)(Int64,##fy#7529::Float64)),0)::Bool)))) goto 0\n",
       "        return (Main.sqrt)($(Expr(:new, Complex{Float64}, :(x::Float64), :((Base.box)(Float64,(Base.sitofp)(Float64,0))))))::Complex{Float64}\n",
       "        0: \n",
       "        return (Base.Math.box)(Base.Math.Float64,(Base.Math.sqrt_llvm)(x::Float64))::Float64\n",
       "    end::Union{Complex{Float64},Float64}))))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysqrt(x) = x < 0 ? sqrt(complex(x)) : sqrt(x)\n",
    "code_typed(mysqrt,Tuple{Float64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Type inference & type stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " :($(Expr(:lambda, Any[:v], Any[Any[Any[:v,Array{Float64,1},0],Any[:s,Float64,2],Any[symbol(\"#s41\"),Int64,2],Any[:i,Int64,18],Any[symbol(\"####fy#7487#7612\"),Float64,18],Any[:_var0,Float64,2],Any[symbol(\"####fy#7487#7613\"),Float64,18],Any[:_var1,Float64,2]],Any[],Any[UnitRange{Int64},Tuple{Int64,Int64},Float64,Int64,Float64,Int64,Int64],Any[]], :(begin  # In[6], line 2:\n",
       "        GenSym(2) = (Base.arrayref)(v::Array{Float64,1},1)::Float64\n",
       "        ####fy#7487#7612 = (Base.box)(Float64,(Base.sitofp)(Float64,0))\n",
       "        unless (Base.box)(Base.Bool,(Base.or_int)((Base.lt_float)(GenSym(2),####fy#7487#7612::Float64)::Bool,(Base.box)(Base.Bool,(Base.and_int)((Base.box)(Base.Bool,(Base.and_int)((Base.eq_float)(GenSym(2),####fy#7487#7612::Float64)::Bool,(Base.lt_float)(####fy#7487#7612::Float64,9.223372036854776e18)::Bool)),(Base.slt_int)((Base.box)(Int64,(Base.fptosi)(Int64,####fy#7487#7612::Float64)),0)::Bool)))) goto 6\n",
       "        _var0 = (Base.box)(Base.Float64,(Base.neg_float)(GenSym(2)))\n",
       "        goto 7\n",
       "        6: \n",
       "        _var0 = GenSym(2)\n",
       "        7: \n",
       "        s = _var0::Float64 # In[6], line 3:\n",
       "        GenSym(3) = (Base.arraylen)(v::Array{Float64,1})::Int64\n",
       "        GenSym(0) = $(Expr(:new, UnitRange{Int64}, 2, :(((top(getfield))(Base.Intrinsics,:select_value)::I)((Base.sle_int)(2,GenSym(3))::Bool,GenSym(3),(Base.box)(Int64,(Base.sub_int)(2,1)))::Int64)))\n",
       "        #s41 = (top(getfield))(GenSym(0),:start)::Int64\n",
       "        unless (Base.box)(Base.Bool,(Base.not_int)(#s41::Int64 === (Base.box)(Base.Int,(Base.add_int)((top(getfield))(GenSym(0),:stop)::Int64,1))::Bool)) goto 1\n",
       "        2: \n",
       "        GenSym(5) = #s41::Int64\n",
       "        GenSym(6) = (Base.box)(Base.Int,(Base.add_int)(#s41::Int64,1))\n",
       "        i = GenSym(5)\n",
       "        #s41 = GenSym(6) # In[6], line 4:\n",
       "        GenSym(4) = (Base.arrayref)(v::Array{Float64,1},i::Int64)::Float64\n",
       "        ####fy#7487#7613 = (Base.box)(Float64,(Base.sitofp)(Float64,0))\n",
       "        unless (Base.box)(Base.Bool,(Base.or_int)((Base.lt_float)(GenSym(4),####fy#7487#7613::Float64)::Bool,(Base.box)(Base.Bool,(Base.and_int)((Base.box)(Base.Bool,(Base.and_int)((Base.eq_float)(GenSym(4),####fy#7487#7613::Float64)::Bool,(Base.lt_float)(####fy#7487#7613::Float64,9.223372036854776e18)::Bool)),(Base.slt_int)((Base.box)(Int64,(Base.fptosi)(Int64,####fy#7487#7613::Float64)),0)::Bool)))) goto 15\n",
       "        _var1 = (Base.box)(Base.Float64,(Base.neg_float)(GenSym(4)))\n",
       "        goto 16\n",
       "        15: \n",
       "        _var1 = GenSym(4)\n",
       "        16: \n",
       "        s = (Base.box)(Base.Float64,(Base.add_float)(s::Float64,_var1::Float64))\n",
       "        3: \n",
       "        unless (Base.box)(Base.Bool,(Base.not_int)((Base.box)(Base.Bool,(Base.not_int)(#s41::Int64 === (Base.box)(Base.Int,(Base.add_int)((top(getfield))(GenSym(0),:stop)::Int64,1))::Bool)))) goto 2\n",
       "        1: \n",
       "        0:  # In[6], line 6:\n",
       "        return Main.x\n",
       "    end))))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function summyabs(v::Vector)\n",
    "    s = myabs(v[1])\n",
    "    for i = 2:length(v)\n",
    "        s += myabs(v[i])\n",
    "    end\n",
    "    return x\n",
    "end\n",
    "code_typed(summyabs,Tuple{Vector{Float64}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Type inference & type stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " :($(Expr(:lambda, Any[:v], Any[Any[Any[:v,Array{Int64,1},0],Any[:s,Union{Complex{Float64},Float64},2],Any[symbol(\"#s41\"),Int64,2],Any[:i,Int64,18],Any[:_var0,Union{Complex{Float64},Float64},2],Any[:_var1,Union{Complex{Float64},Float64},2]],Any[],Any[UnitRange{Int64},Tuple{Int64,Int64},Int64,Complex{Int64},Int64,Int64,Complex{Int64},Int64,Int64],Any[]], :(begin  # In[7], line 2:\n",
       "        GenSym(2) = (Base.arrayref)(v::Array{Int64,1},1)::Int64\n",
       "        unless (Base.slt_int)(GenSym(2),0)::Bool goto 6\n",
       "        GenSym(3) = $(Expr(:new, Complex{Int64}, GenSym(2), 0))\n",
       "        _var0 = (Base.sqrt)($(Expr(:new, Complex{Float64}, :((Base.box)(Float64,(Base.sitofp)(Float64,(top(getfield))(GenSym(3),:re)::Int64))), :((Base.box)(Float64,(Base.sitofp)(Float64,(top(getfield))(GenSym(3),:im)::Int64))))))::Complex{Float64}\n",
       "        goto 7\n",
       "        6: \n",
       "        _var0 = (Base.Math.box)(Base.Math.Float64,(Base.Math.sqrt_llvm)((Base.box)(Float64,(Base.sitofp)(Float64,GenSym(2)))))::Float64\n",
       "        7: \n",
       "        s = _var0::Union{Complex{Float64},Float64} # In[7], line 3:\n",
       "        GenSym(4) = (Base.arraylen)(v::Array{Int64,1})::Int64\n",
       "        GenSym(0) = $(Expr(:new, UnitRange{Int64}, 2, :(((top(getfield))(Base.Intrinsics,:select_value)::I)((Base.sle_int)(2,GenSym(4))::Bool,GenSym(4),(Base.box)(Int64,(Base.sub_int)(2,1)))::Int64)))\n",
       "        #s41 = (top(getfield))(GenSym(0),:start)::Int64\n",
       "        unless (Base.box)(Base.Bool,(Base.not_int)(#s41::Int64 === (Base.box)(Base.Int,(Base.add_int)((top(getfield))(GenSym(0),:stop)::Int64,1))::Bool)) goto 1\n",
       "        2: \n",
       "        GenSym(7) = #s41::Int64\n",
       "        GenSym(8) = (Base.box)(Base.Int,(Base.add_int)(#s41::Int64,1))\n",
       "        i = GenSym(7)\n",
       "        #s41 = GenSym(8) # In[7], line 4:\n",
       "        GenSym(5) = (Base.arrayref)(v::Array{Int64,1},i::Int64)::Int64\n",
       "        unless (Base.slt_int)(GenSym(5),0)::Bool goto 15\n",
       "        GenSym(6) = $(Expr(:new, Complex{Int64}, GenSym(5), 0))\n",
       "        _var1 = (Base.sqrt)($(Expr(:new, Complex{Float64}, :((Base.box)(Float64,(Base.sitofp)(Float64,(top(getfield))(GenSym(6),:re)::Int64))), :((Base.box)(Float64,(Base.sitofp)(Float64,(top(getfield))(GenSym(6),:im)::Int64))))))::Complex{Float64}\n",
       "        goto 16\n",
       "        15: \n",
       "        _var1 = (Base.Math.box)(Base.Math.Float64,(Base.Math.sqrt_llvm)((Base.box)(Float64,(Base.sitofp)(Float64,GenSym(5)))))::Float64\n",
       "        16: \n",
       "        s = s::Union{Complex{Float64},Float64} + _var1::Union{Complex{Float64},Float64}::Union{Complex{Float64},Float64}\n",
       "        3: \n",
       "        unless (Base.box)(Base.Bool,(Base.not_int)((Base.box)(Base.Bool,(Base.not_int)(#s41::Int64 === (Base.box)(Base.Int,(Base.add_int)((top(getfield))(GenSym(0),:stop)::Int64,1))::Bool)))) goto 2\n",
       "        1: \n",
       "        0:  # In[7], line 6:\n",
       "        return Main.x\n",
       "    end))))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function summysqrt(v::Vector)\n",
    "    s = mysqrt(v[1])\n",
    "    for i = 2:length(v)\n",
    "        s += mysqrt(v[i])\n",
    "    end\n",
    "    return x\n",
    "end\n",
    "code_typed(summysqrt,Tuple{Vector{Int64}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Homoiconicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ex=:(function summysqrt(v::Vector)\n",
    "        s = mysqrt(v[1])\n",
    "        for i = 2:length(v)\n",
    "            s += mysqrt(v[i])\n",
    "        end\n",
    "        return x\n",
    "    end);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Expr"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function\n",
      "summysqrt(v::Vector)\n",
      "begin  # In[8], line 2:\n",
      "    s = mysqrt(v[1]) # In[8], line 3:\n",
      "    for i = 2:length(v) # In[8], line 4:\n",
      "        s += mysqrt(v[i])\n",
      "    end # In[8], line 6:\n",
      "    return x\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "println(ex.head),println(ex.args[1]),println(ex.args[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(:function, (:call, :summysqrt, (:(::), :v, :Vector)), (:block,\n",
      "    :( # In[8], line 2:),\n",
      "    (:(=), :s, (:call, :mysqrt, (:ref, :v, 1))),\n",
      "    :( # In[8], line 3:),\n",
      "    (:for, (:(=), :i, (:(:), 2, (:call, :length, :v))), (:block,\n",
      "        :( # In[8], line 4:),\n",
      "        (:+=, :s, (:call, :mysqrt, (:ref, :v, :i)))\n",
      "      )),\n",
      "    :( # In[8], line 6:),\n",
      "    (:return, :x)\n",
      "  ))"
     ]
    }
   ],
   "source": [
    "Meta.show_sexpr(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Metaprogramming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "macro twice(ex)\n",
    "    Expr(:block,ex,ex)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=3;\n",
    "@twice x+=1\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TensorOperations.jl\n",
    "* general tensor operations include permutations, partial traces, contractions\n",
    "    * graphical:\n",
    "      <img src=\"tensorcontraction.png\" style=\"width: 500px;\"/>\n",
    "      \n",
    "    * index notation with Einstein summation convention:\n",
    "      $$D_{a,b,c} = A_{a,d,e,c}\\cdot B_{f,e,b,d,f}+C_{c,b,a}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.646982297870117e-15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=3;\n",
    "A=randn(n,n,n,n);\n",
    "B=randn(n,n,n,n,n);\n",
    "C=randn(n,n,n);\n",
    "\n",
    "D=zeros(n,n,n);\n",
    "for a=1:n, b=1:n, c=1:n\n",
    "    D[a,b,c] += C[c,b,a]\n",
    "    for d=1:n, e=1:n, f=1:n\n",
    "        D[a,b,c] += A[a,d,e,c]*B[f,e,b,d,f]\n",
    "    end\n",
    "end\n",
    "\n",
    "using TensorOperations\n",
    "@tensor D2[a,b,c] := A[a,d,e,c]*B[f,e,b,d,f] + C[c,b,a];\n",
    "\n",
    "@tensor D3[α,β,3] := A[α,'d',-7,3]*B[f,-7,β,'d',f] + C[3,β,α];\n",
    "\n",
    "vecnorm(D-D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "function f1!(D,n,A,B,C)\n",
    "    for a=1:n, b=1:n, c=1:n\n",
    "        D[a,b,c] += C[c,b,a]\n",
    "        for d=1:n, e=1:n, f=1:n\n",
    "            D[a,b,c] += A[a,d,e,c]*B[f,e,b,d,f]\n",
    "        end\n",
    "    end\n",
    "    return D\n",
    "end\n",
    "function f2!(D,n,A,B,C)\n",
    "    @tensor D[a,b,c] = A[a,d,e,c]*B[f,e,b,d,f] + C[c,b,a];\n",
    "    return D\n",
    "end\n",
    "\n",
    "n=30;\n",
    "A=randn(n,n,n,n);\n",
    "B=randn(n,n,n,n,n);\n",
    "C=randn(n,n,n);\n",
    "D=zeros(n,n,n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.023060 seconds (19.33 k allocations: 885.976 KB)\n",
      "  0.174286 seconds (176.65 k allocations: 13.658 MB)\n"
     ]
    }
   ],
   "source": [
    "@time f1!(D,n,A,B,C);\n",
    "@time f2!(D,n,A,B,C);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.733241 seconds (4 allocations: 160 bytes)\n",
      "  0.023584 seconds (158 allocations: 6.599 MB, 40.82% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time f1!(D,n,A,B,C);\n",
    "@time f2!(D,n,A,B,C);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is going on underneath?\n",
    "* **Basic tensor operations** (inspired by BLAS)\n",
    "    * permutations and addition: `C = β*C + α*permutation(op(A))`\n",
    "    * partial trace: `C = β*C + α*partialtrace(op(A))`\n",
    "    * contraction: `C = β*C + α*contract(op(A),op(B))`\n",
    "    \n",
    "  `op` can be idenity (doing nothing) or `conj`\n",
    "    \n",
    "  also available via function based syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementation of basic tensor operations (with metaprogramming)\n",
    "### 1. Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "A=randn(10,10,10,10,10,10,10,10);\n",
    "B=zeros(10,10,10,10,10,10,10,10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.115277 seconds (8.14 k allocations: 414.904 KB)\n",
      "  2.046332 seconds (60.49 k allocations: 2.892 MB)\n",
      "  1.293322 seconds (1.27 M allocations: 63.428 MB)\n"
     ]
    }
   ],
   "source": [
    "@time copy!(B,A);\n",
    "@time permutedims!(B,A,[8,7,6,5,4,3,2,1]);\n",
    "@time @tensor B[8,7,6,5,4,3,2,1] = A[1,2,3,4,5,6,7,8];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.092903 seconds (4 allocations: 160 bytes)\n",
      "  1.960895 seconds (40 allocations: 1.406 KB)\n",
      "  0.293874 seconds (32 allocations: 1.406 KB)\n"
     ]
    }
   ],
   "source": [
    "@time copy!(B,A);\n",
    "@time permutedims!(B,A,[8,7,6,5,4,3,2,1]);\n",
    "@time @tensor B[8,7,6,5,4,3,2,1] = A[1,2,3,4,5,6,7,8];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1. Permutations\n",
    "* How to optimize permutations? Why is it slower than normal copy?\n",
    "* Even for matrix transposition?\n",
    "  ```julia\n",
    "  transpose!(dst,src)```\n",
    "  <img src=\"transpose.png\" style=\"width: 400px;\"/>\n",
    "  Memory is linear $\\Rightarrow$ `transpose` requires unfavorable memory access!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```julia\n",
    "function transpose!(B::StridedMatrix,A::StridedMatrix)\n",
    "    m, n = size(A)\n",
    "    size(B,1) == n && size(B,2) == m || throw(DimensionMismatch(\"transpose\"))\n",
    "\n",
    "    if m*n<=4*transposebaselength\n",
    "        @inbounds begin\n",
    "            for j = 1:n\n",
    "                for i = 1:m\n",
    "                    B[j,i] = transpose(A[i,j])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    else\n",
    "        transposeblock!(B,A,m,n,0,0)\n",
    "    end\n",
    "    return B\n",
    "end\n",
    "function transposeblock!(B::StridedMatrix,A::StridedMatrix,m::Int,n::Int,offseti::Int,offsetj::Int)\n",
    "    if m*n<=transposebaselength\n",
    "        @inbounds begin\n",
    "            for j = offsetj+(1:n)\n",
    "                for i = offseti+(1:m)\n",
    "                    B[j,i] = transpose(A[i,j])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    elseif m>n\n",
    "        newm=m>>1\n",
    "        transposeblock!(B,A,newm,n,offseti,offsetj)\n",
    "        transposeblock!(B,A,m-newm,n,offseti+newm,offsetj)\n",
    "    else\n",
    "        newn=n>>1\n",
    "        transposeblock!(B,A,m,newn,offseti,offsetj)\n",
    "        transposeblock!(B,A,m,n-newn,offseti,offsetj+newn)\n",
    "    end\n",
    "    return B\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1. Permutations\n",
    "* How to generalize to multidimensional permutations?\n",
    "    1. How to write nested loops depending on the dimensionality of the array?\n",
    "    2. What is the best blocking (divide and conquer) strategy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Solution to 1: generated functions!\n",
    "\n",
    "parse -> expressions -> macro expansion -> new expression -> type inference -> generated functions -> compile -> run\n",
    "\n",
    "[TensorOperations.jl kernels](https://github.com/Jutho/TensorOperations.jl/blob/master/src/implementation/kernels.jl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Solution to 2: divide dimensions along which the minimum of the memory jumps of the two arrays is maximal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2. Partial trace\n",
    "* very similar, but somewhat more carefull\n",
    "\n",
    "### 3. Tensor contraction: very similar to matrix multiplication\n",
    "\n",
    "* Fastest algorithm: permute input arrays and reshape them such that you can use BLAS matrix multiplication\n",
    "  <img src=\"simplecontraction.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "```julia\n",
    "Amat=reshape(permutedims(A,[1,4,2,3]),(dA1*dA4,dA2*dA3))\n",
    "Bmat=reshape(permutedims(B,[3,1,2]),(dB3*dB1,dB2))\n",
    "Cmat=Amat*Bmat\n",
    "C=permutedims(reshape(Cmat,(dA1,dA4,dB2)),[1,3,2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "```julia\n",
    "using TensorOperations\n",
    "C = tensorcontract(A,[1,2,3,4],B,[3,5,2],[1,5,4])\n",
    "@tensor C[a,b,c] = A[a,d,e,c]*B[e,b,d]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization of tensor contraction order\n",
    "\n",
    "### Contraction order matters!\n",
    "\n",
    "* matrix - matrix - vector multiplication: `A*B*v`: \n",
    "  \n",
    "  `A*(B*v)` is much faster than `(A*B)*v`\n",
    "\n",
    "\n",
    "* Optimal contraction order in more complicated tensor networks?\n",
    "  <img src=\"mera.png\" style=\"width: 200px;\"/>\n",
    "  \n",
    "* Pairwise contraction is always sufficient, but in which sequence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is optimal contraction sequence?\n",
    "\n",
    "* Manual determination can become laborious task\n",
    "* Contraction of two-dimensional multiscale entanglement renormalization ansatz:\n",
    "  <img src=\"2dmerac.png\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Algorithmic determination of optimal contraction sequence\n",
    "\n",
    "\"Faster identification of optimal contraction sequences for tensor networks\"\n",
    "\n",
    "Robert N. C. Pfeifer, JH, and Frank Verstraete, Phys Rev E 90, 033315 (2014)\n",
    "\n",
    "* Breadth-first constructive approach:\n",
    "  <img src=\"algorithm.png\" style=\"width: 500px;\"/>\n",
    "* Add tricks to make it efficient   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  <img src=\"mera2.png\" style=\"width: 800px;\"/>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 2*x^9 + 4*x^8 + 2*x^6 + 2*x^5\n",
      "tree = ((3,11),((10,8),((5,2),((9,1),(7,(6,4))))))\n"
     ]
    }
   ],
   "source": [
    "using TensorOperations\n",
    "x=TensorOperations.Power(1,1);\n",
    "labels=Any[[-1,1,2],[-2,3,4],[-3,5,6],[2,3,7,8],[4,5,9,10],[7,8,9,11,12,13],\n",
    "    [14,15,11,12],[16,17,13,10],[-4,1,14],[-5,15,16],[-6,17,6]];\n",
    "costW = [x,x,x]\n",
    "costU = [x,x,x,x]\n",
    "costh = [x,x,x,x,x,x]\n",
    "costs = Any[costW,costW,costW,costU,costU,costh,costU,costU,costW,costW,costW]\n",
    "cost,tree=optimizecontract(labels,costs);\n",
    "@show cost;\n",
    "@show tree;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.760331 seconds (1.54 k allocations: 1.094 GB, 37.61% gc time)\n",
      "  0.006819 seconds (1.32 k allocations: 9.754 MB)\n"
     ]
    }
   ],
   "source": [
    "x=6;\n",
    "W1=W2=W3=randn(x,x,x);\n",
    "U1=U2=randn(x,x,x,x);\n",
    "h=randn(x,x,x,x,x,x);\n",
    "@time @tensor begin\n",
    "    result[-1,-2,-3,-4,-5,-6] := \n",
    "        W1[-1,1,2]*W2[-2,3,4]*W3[-3,5,6]*\n",
    "        U1[2,3,7,8]*U2[4,5,9,10]*\n",
    "        h[7,8,9,11,12,13]*\n",
    "        conj(U1)[14,15,11,12]*conj(U2)[16,17,13,10]*\n",
    "        conj(W1)[-4,1,14]*conj(W2)[-5,15,16]*conj(W3)[-6,17,6];\n",
    "end\n",
    "@time @tensoropt χ begin\n",
    "    result2[-1,-2,-3,-4,-5,-6] := \n",
    "        W1[-1,1,2]*W2[-2,3,4]*W3[-3,5,6]*\n",
    "        U1[2,3,7,8]*U2[4,5,9,10]*\n",
    "        h[7,8,9,11,12,13]*\n",
    "        conj(U1)[14,15,11,12]*conj(U2)[16,17,13,10]*\n",
    "        conj(W1)[-4,1,14]*conj(W2)[-5,15,16]*conj(W3)[-6,17,6]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.856717807695058e-16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecnorm(result-result2)/vecnorm(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outlook\n",
    "Possible features that might be added to `TensorOperations.jl` in the future:\n",
    "* More flexible index notation\n",
    "    * to allow for a mixed combination with manual loops in order to take slices\n",
    "    * to automatically specify reshapes: e.g. `C[(a,b),c,d] = A[a,c,e]*B[b,d,e]`\n",
    "* Multi-threading support?\n",
    "    * Currently being implemented in Julia\n",
    "* GPU support\n",
    "* Combine directly with BLAS kernels\n",
    "* ...\n",
    "\n",
    "## Conclusions\n",
    "* Julia is a promising language for developing tensor algorithms (and much more)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.4.1",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
